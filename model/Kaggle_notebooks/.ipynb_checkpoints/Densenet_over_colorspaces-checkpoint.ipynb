{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.activations import *\n",
    "\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import random\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 10, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backend = {\"backend\": tf.keras.backend, \n",
    "          \"layers\": tf.keras.layers, \n",
    "          \"models\": tf.keras.models,\n",
    "          'utils': tf.keras.utils}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_size = (512, 512)\n",
    "model1 = keras_applications.densenet.DenseNet([10, 10, 10, 10],\n",
    "             False,\n",
    "             None,\n",
    "             None,\n",
    "             (*images_size, 3),\n",
    "             'avg',\n",
    "             2,\n",
    "             **backend)\n",
    "\n",
    "model2 = keras_applications.densenet.DenseNet([10, 10, 10, 10],\n",
    "             False,\n",
    "             None,\n",
    "             None,\n",
    "             (*images_size, 3),\n",
    "             'avg',\n",
    "             2,\n",
    "             **backend)\n",
    "\n",
    "model3 = keras_applications.densenet.DenseNet([10, 10, 10, 10],\n",
    "             False,\n",
    "             None,\n",
    "             None,\n",
    "             (*images_size, 3),\n",
    "             'avg',\n",
    "             2,\n",
    "             **backend)\n",
    "\n",
    "model4 = keras_applications.densenet.DenseNet([10, 10, 10, 10],\n",
    "             False,\n",
    "             None,\n",
    "             None,\n",
    "             (*images_size, 3),\n",
    "             'avg',\n",
    "             2,\n",
    "             **backend)\n",
    "\n",
    "model5 = keras_applications.densenet.DenseNet([10, 10, 10, 10],\n",
    "             False,\n",
    "             None,\n",
    "             None,\n",
    "             (*images_size, 3),\n",
    "             'avg',\n",
    "             2,\n",
    "             **backend)\n",
    "\n",
    "model6 = keras_applications.densenet.DenseNet([10, 10, 10, 10],\n",
    "             False,\n",
    "             None,\n",
    "             None,\n",
    "             (*images_size, 3),\n",
    "             'avg',\n",
    "             2,\n",
    "             **backend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input(shape = (*images_size, 3))\n",
    "\n",
    "model_BGR =  Sequential(Model(input_img, model1(input_img)))\n",
    "model_BGR.add(Flatten())\n",
    "\n",
    "model_HSV = Sequential(Model(input_img, model2(input_img)))\n",
    "model_HSV.add(Flatten())\n",
    "\n",
    "\n",
    "# model_YUV = Model(input_img, model(input_img))\n",
    "model_YUV = Sequential(Model(input_img, model3(input_img)))\n",
    "model_YUV.add(Flatten())\n",
    "\n",
    "# model_LAB = Model(input_img, model(input_img))\n",
    "model_LAB = Sequential(Model(input_img, model4(input_img)))\n",
    "model_LAB.add(Flatten())\n",
    "\n",
    "model_HED = Sequential(Model(input_img, model5(input_img)))\n",
    "model_HED.add(Flatten())\n",
    "\n",
    "model_XYZ = Sequential(Model(input_img, model6(input_img)))\n",
    "model_XYZ.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = concatenate(inputs=[model_BGR.output, model_HSV.output, model_YUV.output,\n",
    "                       model_LAB.output, model_HED.output, model_XYZ.output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = Dense(2, activation=\"softmax\")(x)\n",
    "# our model will accept the inputs of the two branches and\n",
    "# then output a single value\n",
    "model_comb = Model(inputs=[model_BGR.input, model_HSV.input, model_YUV.input, \n",
    "                          model_LAB.input, model_HED.input, model_XYZ.input], outputs=z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comb.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.color import rgb2hed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def changeColorSpace(img, flag):\n",
    "    if flag == 'flag_HED':\n",
    "        img = rgb2hed(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        return img#/np.max(img)\n",
    "    else:\n",
    "        img = cv2.cvtColor(img, flag)\n",
    "        return img#/np.max(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_HSV = cv2.COLOR_BGR2HSV\n",
    "flag_YUV = cv2.COLOR_BGR2YUV\n",
    "flag_LAB = cv2.COLOR_BGR2LAB\n",
    "flag_HED = 'flag_HED'\n",
    "flag_XYZ = cv2.COLOR_BGR2XYZ\n",
    "flag_YCR_CB = cv2.COLOR_BGR2YCR_CB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('/kaggle/input/alaska2-image-steganalysis/Cover/00010.jpg')#, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_hed = changeColorSpace(img, flag_HSV)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(7, 6))\n",
    "ax0, ax1, ax2, ax3 = axes.ravel()\n",
    "\n",
    "ax0.imshow(img)\n",
    "ax0.set_title(\"Original image\")\n",
    "\n",
    "ax1.imshow(img_hed[:, :, 0], cmap=plt.cm.gray)\n",
    "\n",
    "ax2.imshow(img_hed[:, :, 1], cmap=plt.cm.gray)\n",
    "#ax2.set_title(\"Eosin\")\n",
    "\n",
    "ax3.imshow(img_hed[:, :, 2], cmap=plt.cm.gray)\n",
    "#ax3.set_title(\"DAB\")\n",
    "\n",
    "for ax in axes.ravel():\n",
    "    ax.axis('off')\n",
    "\n",
    "fig.subplots_adjust(hspace=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_data(image_id, image_size):\n",
    "    img = cv2.imread(image_id)\n",
    "    h, w = image_size\n",
    "    crop_img = img[0:h, 0:w]\n",
    "    return crop_img\n",
    "\n",
    "def get_label(image_id):\n",
    "    if 'Cover' in image_id:\n",
    "        return [1,0]\n",
    "    else:\n",
    "        return [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, batch_size=32, dim=(32,32,32), n_channels=1, \n",
    "                 shuffle=True, number_of_labels=2, flag=None):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "        self.number_of_labels = number_of_labels\n",
    "        self.flag = flag\n",
    "        \n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "        \n",
    "        \"\"\"Getting items from the 2 generators and packing them\"\"\"\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "        # cv2 recevrses height and width\n",
    "        return [X[0], X[1], X[2], X[3], X[4], X[5]], y\n",
    "#         return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "#         X = np.empty((self.batch_size, *self.dim[::-1], self.n_channels))\n",
    "#         y = np.empty((self.batch_size, *self.dim[::-1]))\n",
    "        X = np.empty((6, self.batch_size, *self.dim, self.n_channels))\n",
    "        y = np.empty((self.batch_size, self.number_of_labels))\n",
    "        \n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            # Store sample\n",
    "            img = get_image_data(ID, self.dim)\n",
    "            X[0,i] = img/np.max(img)\n",
    "            X[1,i] = changeColorSpace(img, flag_HSV)\n",
    "            X[2,i] = changeColorSpace(img, flag_YUV)\n",
    "            X[3,i] = changeColorSpace(img, flag_LAB)\n",
    "            X[4,i] = changeColorSpace(img, flag_HED)\n",
    "            X[5,i] = changeColorSpace(img, flag_XYZ)\n",
    "            \n",
    "            y[i,:] = get_label(ID)\n",
    "                    \n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = '/kaggle/input/alaska2-image-steganalysis/'\n",
    "limit = 250\n",
    "cover_imgs = glob.glob(input_dir+'Cover/*.jpg')\n",
    "#random.Random(4).shuffle(cover_imgs)\n",
    "cover_imgs = cover_imgs[:limit]\n",
    "\n",
    "jmipod_imgs = glob.glob(input_dir+'JMiPOD/*.jpg')\n",
    "#random.Random(4).shuffle(jmipod_imgs)\n",
    "jmipod_imgs = jmipod_imgs[:limit]\n",
    "\n",
    "juniward_imgs = glob.glob(input_dir+'JUNIWARD/*.jpg')\n",
    "#random.Random(4).shuffle(juniward_imgs)\n",
    "juniward_imgs = juniward_imgs[:limit]\n",
    "\n",
    "uerd_imgs = glob.glob(input_dir+'UERD/*.jpg')\n",
    "#random.Random(4).shuffle(uerd_imgs)\n",
    "uerd_imgs = uerd_imgs[:limit]\n",
    "\n",
    "list_IDs = cover_imgs + jmipod_imgs + juniward_imgs + uerd_imgs\n",
    "\n",
    "random.Random(4).shuffle(list_IDs)\n",
    "\n",
    "train_IDs = list_IDs[:int(0.8*len(list_IDs))]\n",
    "test_IDs = list_IDs[int(0.8*len(list_IDs)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'dim': images_size,\n",
    "          'batch_size': 1,\n",
    "          'n_channels': 3,\n",
    "          'shuffle': True, }\n",
    "\n",
    "# Generators\n",
    "training_generator = DataGenerator(train_IDs, **params)\n",
    "validation_generator = DataGenerator(test_IDs, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comb.compile(loss=keras.losses.binary_crossentropy, \n",
    "                    metrics=['accuracy'], optimizer='adadelta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comb.fit_generator(generator=training_generator, validation_data=validation_generator, epochs=5, workers=5, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = '/kaggle/input/alaska2-image-steganalysis/'\n",
    "test_imgs = glob.glob(input_dir+'Test/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateTestData(id_list, dim=images_size, n_channels=3):\n",
    "    batch_size = len(id_list)\n",
    "    X = np.empty((6, 1, *dim, n_channels))\n",
    "\n",
    "    # Generate data\n",
    "    for i, ID in enumerate(id_list):\n",
    "        # Store sample\n",
    "        img = get_image_data(ID, dim)\n",
    "        X[0,i] = img/np.max(img)\n",
    "        X[1,i] = changeColorSpace(img, flag_HSV)\n",
    "        X[2,i] = changeColorSpace(img, flag_YUV)\n",
    "        X[3,i] = changeColorSpace(img, flag_LAB)\n",
    "        X[4,i] = changeColorSpace(img, flag_HED)\n",
    "        X[5,i] = changeColorSpace(img, flag_XYZ)\n",
    "    return [X[0], X[1], X[2], X[3], X[4], X[5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for i in range(0, 5000, 1):\n",
    "    X = generateTestData(test_imgs[i:i+1])\n",
    "    y_pred = model_comb.predict(X)\n",
    "    preds.append([test_imgs[i].split('/')[-1], y_pred[0][1]])\n",
    "    if i % 50 == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(preds, columns=[\"Id\", \"Label\"])\n",
    "df.sort_values(['Id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
